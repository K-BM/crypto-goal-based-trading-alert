{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04dd0fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching daily data...\n",
      "\n",
      "Last available data in dataset: 2025-05-18 00:00:00\n",
      "\n",
      "Calculating indicators...\n",
      "\n",
      "Evaluating multiple thresholds...\n",
      "\n",
      "Prediction date: 2025-05-18\n",
      "Current time (UTC+3): 2025-05-18 17:25:14\n",
      "\n",
      "========================================================================================================================\n",
      "                                 SUMMARY OF ALL THRESHOLDS (PRICE DECREASE PREDICTION)                                  \n",
      "========================================================================================================================\n",
      " Threshold (%)  Optimal_Threshold  Test_Accuracy  Test_Precision  Test_Recall  Test_F1  Test_Sensitivity  Test_Specificity  Train_Accuracy  Train_Precision  Train_Recall  Train_F1  Train_Sensitivity  Train_Specificity  Accuracy_Gap  F1_Gap  Latest_Proba  Latest_Pred  Actual_Move  Open_Price  Target_Price Timestamp   Current_Time_UTC+3\n",
      "     0.1              0.20             0.96            0.96          1.00       0.98          1.00              0.04             0.99            0.99            0.99        0.99          0.99               0.73             0.02       0.01       0.50          1            0        103126.65    103023.52   2025-05-18 2025-05-18 17:25:14\n",
      "     0.2              0.16             0.92            0.92          1.00       0.96          1.00              0.08             0.96            0.97            0.99        0.98          0.99               0.46             0.04       0.02       0.41          1            0        103126.65    102920.40   2025-05-18 2025-05-18 17:25:14\n",
      "     0.3              0.19             0.88            0.89          0.98       0.93          0.98              0.20             0.95            0.96            0.99        0.97          0.99               0.56             0.07       0.04       0.24          1            0        103126.65    102817.27   2025-05-18 2025-05-18 17:25:15\n",
      "     0.4              0.18             0.85            0.85          0.99       0.92          0.99              0.18             0.94            0.94            0.99        0.97          0.99               0.49             0.09       0.05       0.23          1            0        103126.65    102714.14   2025-05-18 2025-05-18 17:25:15\n",
      "     0.5              0.23             0.84            0.87          0.93       0.90          0.93              0.51             0.93            0.95            0.97        0.96          0.97               0.69             0.09       0.06       0.10          0            0        103126.65    102611.02   2025-05-18 2025-05-18 17:25:15\n",
      "     0.6              0.25             0.85            0.88          0.92       0.90          0.92              0.62             0.93            0.95            0.97        0.96          0.97               0.74             0.08       0.06       0.08          0            0        103126.65    102507.89   2025-05-18 2025-05-18 17:25:15\n",
      "     0.7              0.23             0.83            0.84          0.94       0.88          0.94              0.57             0.91            0.91            0.97        0.94          0.97               0.65             0.08       0.06       0.09          0            0        103126.65    102404.76   2025-05-18 2025-05-18 17:25:15\n",
      "     0.8              0.24             0.82            0.84          0.91       0.87          0.91              0.66             0.91            0.91            0.97        0.94          0.97               0.71             0.08       0.07       0.11          0            0        103126.65    102301.64   2025-05-18 2025-05-18 17:25:16\n",
      "     0.9              0.29             0.86            0.91          0.86       0.88          0.86              0.85             0.91            0.93            0.95        0.94          0.95               0.81             0.05       0.06       0.10          0            0        103126.65    102198.51   2025-05-18 2025-05-18 17:25:16\n",
      "     1.0              0.28             0.86            0.86          0.90       0.88          0.90              0.80             0.90            0.91            0.94        0.93          0.94               0.79             0.04       0.05       0.09          0            0        103126.65    102095.38   2025-05-18 2025-05-18 17:25:16\n",
      "     1.1              0.33             0.88            0.89          0.89       0.89          0.89              0.86             0.89            0.91            0.93        0.92          0.93               0.82             0.02       0.03       0.11          0            0        103126.65    101992.26   2025-05-18 2025-05-18 17:25:16\n",
      "     1.2              0.31             0.88            0.86          0.91       0.89          0.91              0.84             0.90            0.90            0.94        0.92          0.94               0.81             0.02       0.03       0.07          0            0        103126.65    101889.13   2025-05-18 2025-05-18 17:25:17\n",
      "     1.3              0.22             0.86            0.80          0.94       0.87          0.94              0.77             0.87            0.83            0.98        0.90          0.98               0.69             0.01       0.03       0.06          0            0        103126.65    101786.00   2025-05-18 2025-05-18 17:25:17\n",
      "     1.4              0.34             0.87            0.85          0.87       0.86          0.87              0.87             0.90            0.90            0.94        0.92          0.94               0.85             0.03       0.05       0.07          0            0        103126.65    101682.88   2025-05-18 2025-05-18 17:25:17\n",
      "     1.5              0.50             0.88            0.92          0.79       0.85          0.79              0.95             0.89            0.95            0.85        0.90          0.85               0.94             0.01       0.05       0.04          0            0        103126.65    101579.75   2025-05-18 2025-05-18 17:25:17\n",
      "     1.6              0.42             0.89            0.89          0.85       0.87          0.85              0.93             0.91            0.91            0.91        0.91          0.91               0.90             0.01       0.04       0.03          0            0        103126.65    101476.62   2025-05-18 2025-05-18 17:25:18\n",
      "     1.7              0.43             0.89            0.86          0.87       0.86          0.87              0.91             0.91            0.90            0.92        0.91          0.92               0.89             0.01       0.05       0.02          0            0        103126.65    101373.50   2025-05-18 2025-05-18 17:25:18\n",
      "     1.8              0.38             0.90            0.86          0.88       0.87          0.88              0.92             0.91            0.89            0.94        0.92          0.94               0.89             0.01       0.05       0.05          0            0        103126.65    101270.37   2025-05-18 2025-05-18 17:25:18\n",
      "     1.9              0.44             0.90            0.84          0.87       0.86          0.87              0.92             0.92            0.91            0.92        0.91          0.92               0.92             0.02       0.06       0.04          0            0        103126.65    101167.24   2025-05-18 2025-05-18 17:25:18\n",
      "     2.0              0.47             0.91            0.86          0.88       0.87          0.88              0.93             0.92            0.91            0.92        0.92          0.92               0.93             0.01       0.05       0.02          0            0        103126.65    101064.12   2025-05-18 2025-05-18 17:25:19\n",
      "     2.1              0.49             0.91            0.84          0.88       0.86          0.88              0.93             0.93            0.91            0.93        0.92          0.93               0.93             0.02       0.06       0.02          0            0        103126.65    100960.99   2025-05-18 2025-05-18 17:25:19\n",
      "     2.2              0.36             0.91            0.80          0.92       0.85          0.92              0.90             0.92            0.86            0.96        0.91          0.96               0.89             0.01       0.05       0.01          0            0        103126.65    100857.86   2025-05-18 2025-05-18 17:25:19\n",
      "     2.3              0.30             0.91            0.78          0.95       0.86          0.95              0.89             0.91            0.83            0.98        0.90          0.98               0.86             0.00       0.04       0.02          0            0        103126.65    100754.74   2025-05-18 2025-05-18 17:25:20\n",
      "     2.4              0.54             0.92            0.83          0.88       0.85          0.88              0.94             0.94            0.92            0.91        0.92          0.91               0.95             0.01       0.06       0.04          0            0        103126.65    100651.61   2025-05-18 2025-05-18 17:25:20\n",
      "     2.5              0.58             0.93            0.85          0.87       0.86          0.87              0.95             0.94            0.93            0.90        0.91          0.90               0.96             0.01       0.05       0.09          0            0        103126.65    100548.48   2025-05-18 2025-05-18 17:25:20\n",
      "     2.6              0.59             0.94            0.88          0.86       0.87          0.86              0.96             0.94            0.93            0.91        0.92          0.91               0.96             0.00       0.05       0.05          0            0        103126.65    100445.36   2025-05-18 2025-05-18 17:25:20\n",
      "     2.7              0.62             0.93            0.83          0.84       0.84          0.84              0.95             0.95            0.94            0.91        0.92          0.91               0.97             0.02       0.08       0.04          0            0        103126.65    100342.23   2025-05-18 2025-05-18 17:25:21\n",
      "     2.8              0.57             0.93            0.82          0.87       0.84          0.87              0.95             0.95            0.91            0.93        0.92          0.93               0.96             0.02       0.08       0.02          0            0        103126.65    100239.10   2025-05-18 2025-05-18 17:25:21\n",
      "     2.9              0.73             0.95            0.88          0.83       0.86          0.83              0.97             0.95            0.95            0.88        0.91          0.88               0.98             0.00       0.05       0.01          0            0        103126.65    100135.98   2025-05-18 2025-05-18 17:25:21\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from ta.trend import MACD\n",
    "from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.trend import SMAIndicator\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (accuracy_score, precision_score, \n",
    "                           recall_score, f1_score, confusion_matrix,\n",
    "                           precision_recall_curve)\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ======================\n",
    "# PARAMETERS\n",
    "# ======================\n",
    "THRESHOLD_PCT = np.arange(0.1, 3, 0.1)  # Percentage decrease thresholds to evaluate\n",
    "SYMBOL = \"BTCUSDT\"\n",
    "START_DATE = \"1 Jan 2012\"\n",
    "TEST_SIZE = 0.4  # Holdout set size\n",
    "\n",
    "# ======================\n",
    "# DATA FETCHING\n",
    "# ======================\n",
    "client = Client(api_key='your_api_key', api_secret='your_api_secret')\n",
    "\n",
    "def fetch_daily_data(symbol, start_str, end_date=None):\n",
    "    \"\"\"Fetch raw daily candlestick data from Binance\"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now()\n",
    "    else:\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    start_ts = int(pd.to_datetime(start_str).timestamp() * 1000)\n",
    "    all_data = []\n",
    "    \n",
    "    while True:\n",
    "        candles = client.get_klines(\n",
    "            symbol=symbol,\n",
    "            interval=Client.KLINE_INTERVAL_1DAY,\n",
    "            startTime=start_ts,\n",
    "            limit=1000\n",
    "        )\n",
    "        \n",
    "        if not candles:\n",
    "            break\n",
    "            \n",
    "        df = pd.DataFrame(candles, columns=[\n",
    "            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "            'close_time', 'quote_asset_volume', 'trades',\n",
    "            'taker_buy_base', 'taker_buy_quote', 'ignore'\n",
    "        ])\n",
    "        \n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        df = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "        all_data.append(df)\n",
    "        \n",
    "        # Get the last timestamp in the dataframe\n",
    "        last_timestamp = df.index[-1]\n",
    "        \n",
    "        # Check if we've reached the end date\n",
    "        if last_timestamp >= end_date:\n",
    "            break\n",
    "            \n",
    "        # Set the new start time to the next day after the last candle\n",
    "        start_ts = int((last_timestamp + timedelta(days=1)).timestamp() * 1000)\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    full_df = pd.concat(all_data).drop_duplicates()\n",
    "    # Ensure we don't exceed the end_date\n",
    "    return full_df[full_df.index <= end_date]\n",
    "\n",
    "# ======================\n",
    "# FEATURE ENGINEERING\n",
    "# ======================\n",
    "def calculate_daily_indicators(daily_df):\n",
    "    \"\"\"Calculate all technical indicators on daily data\"\"\"\n",
    "    df = daily_df.copy()\n",
    "    \n",
    "    # Ensure no lookahead bias by using shifted close prices\n",
    "    df['close_shifted'] = df['close'].shift(1)\n",
    "    df['high_shifted'] = df['high'].shift(1)\n",
    "    df['low_shifted'] = df['low'].shift(1)\n",
    "    \n",
    "    # Momentum Indicators\n",
    "    df['rsi'] = RSIIndicator(df['close_shifted'], window=14).rsi()\n",
    "    stoch = StochasticOscillator(\n",
    "        high=df['high_shifted'],\n",
    "        low=df['low_shifted'],\n",
    "        close=df['close_shifted'],\n",
    "        window=14,\n",
    "        smooth_window=3\n",
    "    )\n",
    "    df['stoch_k'] = stoch.stoch()\n",
    "    df['stoch_d'] = stoch.stoch_signal()\n",
    "    \n",
    "    # Trend Indicators\n",
    "    macd = MACD(df['close_shifted'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    df['macd'] = macd.macd()\n",
    "    df['macd_signal'] = macd.macd_signal()\n",
    "    df['macd_diff'] = macd.macd_diff()\n",
    "    \n",
    "    # Moving Averages\n",
    "    for window in [9, 20, 50, 100, 200]:\n",
    "        df[f'ma_{window}'] = SMAIndicator(df['close_shifted'], window=window).sma_indicator()\n",
    "    \n",
    "    # Volatility Indicators\n",
    "    bb = BollingerBands(df['close_shifted'], window=20, window_dev=2)\n",
    "    df['bb_upper'] = bb.bollinger_hband()\n",
    "    df['bb_lower'] = bb.bollinger_lband()\n",
    "    df['bb_width'] = bb.bollinger_wband()\n",
    "    \n",
    "    # Lag Features\n",
    "    for feature in ['rsi', 'stoch_k', 'macd', 'ma_9', 'bb_width']:\n",
    "        for lag in [1, 3, 5, 7, 14]:  # 1d, 3d, 5d, 1w, 2w lags\n",
    "            df[f'{feature}_lag{lag}'] = df[feature].shift(lag)\n",
    "    \n",
    "    # Market Context Features\n",
    "    df['daily_return'] = df['close'].pct_change()\n",
    "    df['volatility_7d'] = df['daily_return'].rolling(7).std()\n",
    "    df['volume_ma_7d'] = df['volume'].rolling(7).mean()\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "def create_daily_dataset(daily_df, threshold_pct):\n",
    "    \"\"\"Create the final dataset with target variable\"\"\"\n",
    "    df = daily_df.copy()\n",
    "    \n",
    "    # MODIFIED: Create target for price DECREASE - did price fall below threshold?\n",
    "    df['target'] = (df['low'] <= df['open'] * (1 - threshold_pct/100)).astype(int)\n",
    "    \n",
    "    # Add market open context\n",
    "    df['overnight_return'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "    df['intraday_range'] = (df['high'] - df['low']) / df['open']\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# ======================\n",
    "# MODEL TRAINING & EVALUATION\n",
    "# ======================\n",
    "def prepare_features(daily_df):\n",
    "    \"\"\"Select final features and split data\"\"\"\n",
    "    # Exclude raw prices and forward-looking data\n",
    "    exclude = ['open', 'high', 'low', 'close', 'volume', 'target']\n",
    "    features = [col for col in daily_df.columns if col not in exclude]\n",
    "    \n",
    "    X = daily_df[features]\n",
    "    y = daily_df['target']\n",
    "    \n",
    "    # Time-based split\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Enhanced evaluation with threshold optimization\"\"\"\n",
    "    # Get predictions\n",
    "    y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Find optimal threshold on TRAIN set\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_proba_train)\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    # Evaluate both sets at optimal threshold\n",
    "    y_pred_train = (y_proba_train >= optimal_threshold).astype(int)\n",
    "    y_pred_test = (y_proba_test >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    def get_metrics(y_true, y_pred):\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        return accuracy, precision, recall, f1, tn, fp, fn, tp\n",
    "    \n",
    "    train_metrics = get_metrics(y_train, y_pred_train)\n",
    "    test_metrics = get_metrics(y_test, y_pred_test)\n",
    "    \n",
    "    # Print comparison\n",
    "    print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
    "    print(\"\\n{:<15} {:<10} {:<10} {:<10} {:<10}\".format(\n",
    "        'Set', 'Accuracy', 'Precision', 'Recall', 'F1'))\n",
    "    print(\"{:<15} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
    "        'Train', train_metrics[0], train_metrics[1], train_metrics[2], train_metrics[3]))\n",
    "    print(\"{:<15} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
    "        'Test', test_metrics[0], test_metrics[1], test_metrics[2], test_metrics[3]))\n",
    "    \n",
    "    print(\"\\nTrain Confusion Matrix:\")\n",
    "    print(f\"[[TN: {train_metrics[4]} FP: {train_metrics[5]}]\")\n",
    "    print(f\" [FN: {train_metrics[6]} TP: {train_metrics[7]}]]\")\n",
    "    \n",
    "    print(\"\\nTest Confusion Matrix:\")\n",
    "    print(f\"[[TN: {test_metrics[4]} FP: {test_metrics[5]}]\")\n",
    "    print(f\" [FN: {test_metrics[6]} TP: {test_metrics[7]}]]\")\n",
    "    \n",
    "    # Calculate overfitting gap\n",
    "    overfitting_gap = train_metrics[3] - test_metrics[3]\n",
    "    print(f\"\\nOverfitting Gap (F1): {overfitting_gap:.4f}\")\n",
    "    \n",
    "    if overfitting_gap > 0.1:\n",
    "        print(\"\\nWarning: Potential overfitting (F1 gap > 0.1)\")\n",
    "    elif overfitting_gap > 0.05:\n",
    "        print(\"\\nNote: Moderate overfitting (F1 gap > 0.05)\")\n",
    "    else:\n",
    "        print(\"\\nNo significant overfitting detected\")\n",
    "    \n",
    "    return y_proba_test, optimal_threshold\n",
    "\n",
    "# ======================\n",
    "# MODIFIED MAIN EXECUTION FOR MULTIPLE THRESHOLDS\n",
    "# ======================\n",
    "def evaluate_multiple_thresholds(daily_with_indicators, threshold_list):\n",
    "    \"\"\"Evaluate model performance across multiple threshold percentages with consistent test set\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Create base dataset (without target)\n",
    "    daily_data_full = create_daily_dataset(daily_with_indicators, threshold_pct=1.0)  # Dummy threshold\n",
    "    X_full = daily_data_full[[c for c in daily_data_full.columns if c not in ['open','high','low','close','volume','target']]]\n",
    "    \n",
    "    # Single time-based split for all thresholds\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_idx, test_idx in tscv.split(X_full):\n",
    "        X_train, X_test = X_full.iloc[train_idx], X_full.iloc[test_idx]\n",
    "        y_train_all, y_test_all = daily_data_full.iloc[train_idx], daily_data_full.iloc[test_idx]\n",
    "    \n",
    "    # Get consistent latest observation across all thresholds\n",
    "    last_data = X_test.iloc[[-1]]\n",
    "    last_timestamp = last_data.index[0]\n",
    "    last_open = daily_data_full.loc[last_timestamp, 'open']\n",
    "    last_low = daily_data_full.loc[last_timestamp, 'low']\n",
    "    \n",
    "    for threshold_pct in threshold_list:\n",
    "        \n",
    "        # Create targets for price DECREASE using consistent splits\n",
    "        y_train = (y_train_all['low'] <= y_train_all['open']*(1 - threshold_pct/100)).astype(int)\n",
    "        y_test = (y_test_all['low'] <= y_test_all['open']*(1 - threshold_pct/100)).astype(int)\n",
    "        \n",
    "        # Train model\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            max_depth=4,\n",
    "            learning_rate=0.03,\n",
    "            n_estimators=150,\n",
    "            scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),\n",
    "            early_stopping_rounds=20\n",
    "        )\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Optimal threshold selection\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "        f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
    "        optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        \n",
    "        # Latest prediction\n",
    "        last_proba = model.predict_proba(last_data)[0,1]\n",
    "        last_pred = int(last_proba >= optimal_threshold)\n",
    "        actual_move = int(last_low <= last_open*(1 - threshold_pct/100))\n",
    "        \n",
    "        # Test set metrics\n",
    "        y_pred = (y_proba >= optimal_threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        # Get train predictions and metrics\n",
    "        y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_pred_train = (y_proba_train >= optimal_threshold).astype(int)\n",
    "        tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_pred_train).ravel()\n",
    "\n",
    "        results.append({\n",
    "            'Threshold (%)': threshold_pct,\n",
    "            'Optimal_Threshold': optimal_threshold,\n",
    "            \n",
    "            # Test metrics\n",
    "            'Test_Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Test_Precision': precision_score(y_test, y_pred),\n",
    "            'Test_Recall': recall_score(y_test, y_pred),\n",
    "            'Test_F1': f1_score(y_test, y_pred),\n",
    "            'Test_Sensitivity': tp/(tp+fn),\n",
    "            'Test_Specificity': tn/(tn+fp),\n",
    "            \n",
    "            # Train metrics\n",
    "            'Train_Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "            'Train_Precision': precision_score(y_train, y_pred_train),\n",
    "            'Train_Recall': recall_score(y_train, y_pred_train),\n",
    "            'Train_F1': f1_score(y_train, y_pred_train),\n",
    "            'Train_Sensitivity': tp_train/(tp_train+fn_train),\n",
    "            'Train_Specificity': tn_train/(tn_train+fp_train),\n",
    "            \n",
    "            # Overfitting gaps\n",
    "            'Accuracy_Gap': accuracy_score(y_train, y_pred_train) - accuracy_score(y_test, y_pred),\n",
    "            'F1_Gap': f1_score(y_train, y_pred_train) - f1_score(y_test, y_pred),\n",
    "            \n",
    "            # Prediction info\n",
    "            'Latest_Proba': last_proba,\n",
    "            'Latest_Pred': last_pred,\n",
    "            'Actual_Move': actual_move,\n",
    "            'Open_Price': last_open,\n",
    "            'Target_Price': last_open * (1 - threshold_pct/100),  # Price DECREASE target\n",
    "            'Timestamp': last_timestamp.strftime('%Y-%m-%d'),\n",
    "            'Current_Time_UTC+3': (datetime.utcnow() + timedelta(hours=3)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Fetching daily data...\")\n",
    "    daily_data = fetch_daily_data(SYMBOL, START_DATE)\n",
    "    \n",
    "    # Print last available datetime in dataset\n",
    "    last_data_datetime = daily_data.index[-1]\n",
    "    print(f\"\\nLast available data in dataset: {last_data_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    print(\"\\nCalculating indicators...\")\n",
    "    daily_with_indicators = calculate_daily_indicators(daily_data)\n",
    "    \n",
    "    print(\"\\nEvaluating multiple thresholds...\")\n",
    "    results_df = evaluate_multiple_thresholds(daily_with_indicators, THRESHOLD_PCT)\n",
    "    \n",
    "    # Get prediction date (last date in test set)\n",
    "    prediction_date = pd.to_datetime(results_df['Timestamp'].iloc[0])\n",
    "    print(f\"\\nPrediction date: {prediction_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Current time (UTC+3): {results_df['Current_Time_UTC+3'].iloc[0]}\")\n",
    "    \n",
    "    # Print summary of all thresholds\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"SUMMARY OF ALL THRESHOLDS (PRICE DECREASE PREDICTION)\".center(120))\n",
    "    print(\"=\"*120)\n",
    "    print(results_df.round(2).to_string(index=False, justify='center'))\n",
    "    print(\"=\"*120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
