{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e831d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from binance.client import Client\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "from ta.trend import MACD, SMAIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04dd0fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching hourly data...\n",
      "Calculating indicators...\n",
      "Evaluating multiple thresholds...\n",
      "2025-05-18 00:00:00\n",
      "\n",
      "========================================================================================================================\n",
      "                                 SUMMARY OF ALL THRESHOLDS (PRICE DECREASE PREDICTION)                                  \n",
      "========================================================================================================================\n",
      " Threshold (%)  Optimal_Threshold  Test_Accuracy  Test_Precision  Test_Recall  Test_F1  Test_Sensitivity  Test_Specificity  Train_Accuracy  Train_Precision  Train_Recall  Train_F1  Train_Sensitivity  Train_Specificity  Accuracy_Gap  F1_Gap  Latest_Proba  Latest_Pred  Actual_Move  Open_Price  Target_Price Timestamp   Current_Time_UTC+3\n",
      "     0.1              0.12             0.96            0.96          1.00       0.98          1.00              0.00             0.98            0.98            1.00        0.99          1.00               0.25             0.02       0.01       0.98          1            1        102939.52    102836.58   2025-05-18 2025-05-17 19:50:55\n",
      "     0.2              0.10             0.91            0.91          1.00       0.95          1.00              0.02             0.95            0.95            1.00        0.98          1.00               0.13             0.04       0.02       0.93          1            0        102939.52    102733.64   2025-05-18 2025-05-17 19:50:57\n",
      "     0.3              0.11             0.88            0.88          1.00       0.94          1.00              0.11             0.93            0.93            1.00        0.96          1.00               0.18             0.05       0.03       0.94          1            0        102939.52    102630.70   2025-05-18 2025-05-17 19:50:59\n",
      "     0.4              0.18             0.84            0.85          0.98       0.91          0.98              0.19             0.94            0.94            0.99        0.97          0.99               0.54             0.10       0.06       0.90          1            0        102939.52    102527.76   2025-05-18 2025-05-17 19:51:01\n",
      "     0.5              0.22             0.81            0.83          0.95       0.89          0.95              0.36             0.93            0.94            0.98        0.96          0.98               0.63             0.12       0.07       0.88          1            0        102939.52    102424.82   2025-05-18 2025-05-17 19:51:03\n",
      "     0.6              0.35             0.81            0.86          0.88       0.87          0.88              0.63             0.91            0.98            0.92        0.95          0.92               0.89             0.10       0.08       0.86          1            0        102939.52    102321.88   2025-05-18 2025-05-17 19:51:04\n",
      "     0.7              0.33             0.83            0.86          0.89       0.87          0.89              0.68             0.92            0.96            0.94        0.95          0.94               0.86             0.10       0.08       0.85          1            0        102939.52    102218.94   2025-05-18 2025-05-17 19:51:06\n",
      "     0.8              0.37             0.83            0.85          0.88       0.87          0.88              0.72             0.92            0.97            0.92        0.94          0.92               0.90             0.09       0.08       0.69          1            0        102939.52    102116.00   2025-05-18 2025-05-17 19:51:08\n",
      "     0.9              0.41             0.83            0.86          0.86       0.86          0.86              0.78             0.90            0.97            0.90        0.93          0.90               0.93             0.07       0.07       0.73          1            0        102939.52    102013.06   2025-05-18 2025-05-17 19:51:09\n",
      "     1.0              0.34             0.81            0.79          0.88       0.84          0.88              0.72             0.92            0.94            0.94        0.94          0.94               0.87             0.11       0.11       0.47          1            0        102939.52    101910.12   2025-05-18 2025-05-17 19:51:11\n",
      "     1.1              0.48             0.83            0.85          0.81       0.83          0.81              0.85             0.91            0.98            0.88        0.93          0.88               0.96             0.08       0.10       0.70          1            0        102939.52    101807.19   2025-05-18 2025-05-17 19:51:13\n",
      "     1.2              0.43             0.84            0.83          0.84       0.83          0.84              0.83             0.92            0.97            0.91        0.94          0.91               0.94             0.08       0.10       0.21          0            0        102939.52    101704.25   2025-05-18 2025-05-17 19:51:14\n",
      "     1.3              0.50             0.86            0.88          0.81       0.84          0.81              0.90             0.91            0.97            0.88        0.92          0.88               0.96             0.05       0.08       0.18          0            0        102939.52    101601.31   2025-05-18 2025-05-17 19:51:16\n",
      "     1.4              0.47             0.87            0.84          0.85       0.85          0.85              0.88             0.92            0.96            0.90        0.93          0.90               0.95             0.05       0.08       0.27          0            0        102939.52    101498.37   2025-05-18 2025-05-17 19:51:18\n",
      "     1.5              0.40             0.86            0.81          0.87       0.84          0.87              0.86             0.92            0.94            0.93        0.94          0.93               0.91             0.06       0.10       0.14          0            0        102939.52    101395.43   2025-05-18 2025-05-17 19:51:19\n",
      "     1.6              0.50             0.88            0.87          0.80       0.83          0.80              0.92             0.92            0.96            0.90        0.93          0.90               0.95             0.05       0.09       0.16          0            0        102939.52    101292.49   2025-05-18 2025-05-17 19:51:21\n",
      "     1.7              0.60             0.88            0.88          0.76       0.81          0.76              0.94             0.91            0.98            0.85        0.91          0.85               0.98             0.03       0.10       0.10          0            0        102939.52    101189.55   2025-05-18 2025-05-17 19:51:23\n",
      "     1.8              0.55             0.89            0.85          0.79       0.82          0.79              0.93             0.93            0.96            0.89        0.92          0.89               0.97             0.04       0.10       0.04          0            0        102939.52    101086.61   2025-05-18 2025-05-17 19:51:24\n",
      "     1.9              0.54             0.90            0.86          0.82       0.83          0.82              0.94             0.93            0.95            0.90        0.93          0.90               0.96             0.03       0.09       0.05          0            0        102939.52    100983.67   2025-05-18 2025-05-17 19:51:26\n",
      "     2.0              0.49             0.90            0.83          0.83       0.83          0.83              0.93             0.94            0.93            0.94        0.93          0.94               0.94             0.04       0.10       0.06          0            0        102939.52    100880.73   2025-05-18 2025-05-17 19:51:27\n",
      "     2.1              0.41             0.89            0.78          0.86       0.81          0.86              0.91             0.93            0.89            0.96        0.93          0.96               0.90             0.04       0.11       0.08          0            0        102939.52    100777.79   2025-05-18 2025-05-17 19:51:29\n",
      "     2.2              0.48             0.90            0.83          0.81       0.82          0.81              0.94             0.93            0.91            0.94        0.93          0.94               0.93             0.03       0.10       0.03          0            0        102939.52    100674.85   2025-05-18 2025-05-17 19:51:31\n",
      "     2.3              0.42             0.90            0.80          0.82       0.81          0.82              0.93             0.93            0.87            0.96        0.92          0.96               0.90             0.03       0.11       0.02          0            0        102939.52    100571.91   2025-05-18 2025-05-17 19:51:32\n",
      "     2.4              0.45             0.92            0.83          0.82       0.82          0.82              0.95             0.93            0.89            0.96        0.92          0.96               0.92             0.02       0.09       0.02          0            0        102939.52    100468.97   2025-05-18 2025-05-17 19:51:34\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from ta.trend import MACD\n",
    "from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.trend import SMAIndicator\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (accuracy_score, precision_score, \n",
    "                           recall_score, f1_score, confusion_matrix,\n",
    "                           precision_recall_curve)\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ======================\n",
    "# PARAMETERS\n",
    "# ======================\n",
    "THRESHOLD_PCT = np.arange(0.1, 2.5, 0.1)  # Percentage decrease thresholds to evaluate\n",
    "SYMBOL = \"BTCUSDT\"\n",
    "START_DATE = \"1 Jan 2012\"\n",
    "TEST_SIZE = 0.4  # Holdout set size\n",
    "\n",
    "# ======================\n",
    "# DATA FETCHING\n",
    "# ======================\n",
    "client = Client(api_key='your_api_key', api_secret='your_api_secret')\n",
    "\n",
    "def fetch_hourly_data(symbol, start_str, end_date=None):\n",
    "    \"\"\"Fetch raw hourly candlestick data from Binance\"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now()\n",
    "    else:\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    start_ts = int(pd.to_datetime(start_str).timestamp() * 1000)\n",
    "    all_data = []\n",
    "    \n",
    "    while True:\n",
    "        candles = client.get_klines(\n",
    "            symbol=symbol,\n",
    "            interval=Client.KLINE_INTERVAL_1HOUR,\n",
    "            startTime=start_ts,\n",
    "            limit=1000\n",
    "        )\n",
    "        \n",
    "        if not candles:\n",
    "            break\n",
    "            \n",
    "        df = pd.DataFrame(candles, columns=[\n",
    "            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "            'close_time', 'quote_asset_volume', 'trades',\n",
    "            'taker_buy_base', 'taker_buy_quote', 'ignore'\n",
    "        ])\n",
    "        \n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        df = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "        all_data.append(df)\n",
    "        \n",
    "        # Get the last timestamp in the dataframe\n",
    "        last_timestamp = df.index[-1]\n",
    "        \n",
    "        # Check if we've reached the end date\n",
    "        if last_timestamp >= end_date:\n",
    "            break\n",
    "            \n",
    "        # Set the new start time to the next hour after the last candle\n",
    "        start_ts = int((last_timestamp + timedelta(hours=1)).timestamp() * 1000)\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    full_df = pd.concat(all_data).drop_duplicates()\n",
    "    # Ensure we don't exceed the end_date\n",
    "    return full_df[full_df.index <= end_date]\n",
    "\n",
    "# ======================\n",
    "# FEATURE ENGINEERING\n",
    "# ======================\n",
    "def calculate_hourly_indicators(hourly_df):\n",
    "    \"\"\"Calculate all technical indicators on hourly data\"\"\"\n",
    "    df = hourly_df.copy()\n",
    "    \n",
    "    # Ensure no lookahead bias by using shifted close prices\n",
    "    df['close_shifted'] = df['close'].shift(1)\n",
    "    df['high_shifted'] = df['high'].shift(1)\n",
    "    df['low_shifted'] = df['low'].shift(1)\n",
    "    \n",
    "    # Momentum Indicators\n",
    "    df['rsi'] = RSIIndicator(df['close_shifted'], window=14).rsi()\n",
    "    stoch = StochasticOscillator(\n",
    "        high=df['high_shifted'],\n",
    "        low=df['low_shifted'],\n",
    "        close=df['close_shifted'],\n",
    "        window=14,\n",
    "        smooth_window=3\n",
    "    )\n",
    "    df['stoch_k'] = stoch.stoch()\n",
    "    df['stoch_d'] = stoch.stoch_signal()\n",
    "    \n",
    "    # Trend Indicators\n",
    "    macd = MACD(df['close_shifted'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    df['macd'] = macd.macd()\n",
    "    df['macd_signal'] = macd.macd_signal()\n",
    "    df['macd_diff'] = macd.macd_diff()\n",
    "    \n",
    "    # Moving Averages\n",
    "    for window in [9, 20, 50, 100, 200]:\n",
    "        df[f'ma_{window}'] = SMAIndicator(df['close_shifted'], window=window).sma_indicator()\n",
    "    \n",
    "    # Volatility Indicators\n",
    "    bb = BollingerBands(df['close_shifted'], window=20, window_dev=2)\n",
    "    df['bb_upper'] = bb.bollinger_hband()\n",
    "    df['bb_lower'] = bb.bollinger_lband()\n",
    "    df['bb_width'] = bb.bollinger_wband()\n",
    "    \n",
    "    # Lag Features\n",
    "    for feature in ['rsi', 'stoch_k', 'macd', 'ma_9', 'bb_width']:\n",
    "        for lag in [1, 3, 6, 12, 24]:  # 1h, 3h, 6h, 12h, 1d lags\n",
    "            df[f'{feature}_lag{lag}'] = df[feature].shift(lag)\n",
    "    \n",
    "    # Market Context Features\n",
    "    df['hourly_return'] = df['close'].pct_change()\n",
    "    df['volatility_24h'] = df['hourly_return'].rolling(24).std()\n",
    "    df['volume_ma_24h'] = df['volume'].rolling(24).mean()\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "def create_daily_dataset(hourly_df, threshold_pct):\n",
    "    \"\"\"Resample hourly data to 18:00-18:00 UTC days and create target for price decreases\"\"\"\n",
    "    hourly_df.index = hourly_df.index + pd.Timedelta(hours=8)\n",
    "    print(hourly_df.index[-1])\n",
    "\n",
    "    # Aggregate OHLCV\n",
    "    daily_df = hourly_df[['open', 'high', 'low', 'close', 'volume']].resample('1D').agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "\n",
    "    # # Get the date of the last row in the index\n",
    "    # last_day = hourly_df.index[-1].date()\n",
    "\n",
    "    # # Filter out rows from the last day\n",
    "    # hourly_df_filtered = hourly_df[hourly_df.index.date != last_day]\n",
    "\n",
    "    # # Now resample the filtered DataFrame\n",
    "    # daily_df = hourly_df_filtered[['open', 'high', 'low', 'close', 'volume']].resample('1D').agg({\n",
    "    #     'open': 'first',\n",
    "    #     'high': 'max',\n",
    "    #     'low': 'min',\n",
    "    #     'close': 'last',\n",
    "    #     'volume': 'sum'\n",
    "    # })\n",
    "\n",
    "    \n",
    "    # Resample indicators (take last value of the day)\n",
    "    indicator_cols = [col for col in hourly_df.columns if col not in ['open', 'high', 'low', 'close', 'volume']]\n",
    "    for col in indicator_cols:\n",
    "        daily_df[col] = hourly_df[col].resample('1D').last()\n",
    "    \n",
    "    # MODIFIED: Create target for price DECREASE - did price fall below threshold?\n",
    "    daily_df['target'] = (daily_df['low'] <= daily_df['open'] * (1 - threshold_pct/100)).astype(int)\n",
    "    \n",
    "    # Add market open context\n",
    "    daily_df['overnight_return'] = (daily_df['open'] - daily_df['close'].shift(1)) / daily_df['close'].shift(1)\n",
    "    daily_df['intraday_range'] = (daily_df['high'] - daily_df['low']) / daily_df['open']\n",
    "    \n",
    "    return daily_df.dropna()\n",
    "\n",
    "# ======================\n",
    "# MODEL TRAINING & EVALUATION\n",
    "# ======================\n",
    "def prepare_features(daily_df):\n",
    "    \"\"\"Select final features and split data\"\"\"\n",
    "    # Exclude raw prices and forward-looking data\n",
    "    exclude = ['open', 'high', 'low', 'close', 'volume', 'target']\n",
    "    features = [col for col in daily_df.columns if col not in exclude]\n",
    "    \n",
    "    X = daily_df[features]\n",
    "    y = daily_df['target']\n",
    "    \n",
    "    # Time-based split\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Enhanced evaluation with threshold optimization\"\"\"\n",
    "    # Get predictions\n",
    "    y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Find optimal threshold on TRAIN set\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_proba_train)\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    # Evaluate both sets at optimal threshold\n",
    "    y_pred_train = (y_proba_train >= optimal_threshold).astype(int)\n",
    "    y_pred_test = (y_proba_test >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    def get_metrics(y_true, y_pred):\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        return accuracy, precision, recall, f1, tn, fp, fn, tp\n",
    "    \n",
    "    train_metrics = get_metrics(y_train, y_pred_train)\n",
    "    test_metrics = get_metrics(y_test, y_pred_test)\n",
    "    \n",
    "    # Print comparison\n",
    "    print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
    "    print(\"\\n{:<15} {:<10} {:<10} {:<10} {:<10}\".format(\n",
    "        'Set', 'Accuracy', 'Precision', 'Recall', 'F1'))\n",
    "    print(\"{:<15} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
    "        'Train', train_metrics[0], train_metrics[1], train_metrics[2], train_metrics[3]))\n",
    "    print(\"{:<15} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
    "        'Test', test_metrics[0], test_metrics[1], test_metrics[2], test_metrics[3]))\n",
    "    \n",
    "    print(\"\\nTrain Confusion Matrix:\")\n",
    "    print(f\"[[TN: {train_metrics[4]} FP: {train_metrics[5]}]\")\n",
    "    print(f\" [FN: {train_metrics[6]} TP: {train_metrics[7]}]]\")\n",
    "    \n",
    "    print(\"\\nTest Confusion Matrix:\")\n",
    "    print(f\"[[TN: {test_metrics[4]} FP: {test_metrics[5]}]\")\n",
    "    print(f\" [FN: {test_metrics[6]} TP: {test_metrics[7]}]]\")\n",
    "    \n",
    "    # Calculate overfitting gap\n",
    "    overfitting_gap = train_metrics[3] - test_metrics[3]\n",
    "    print(f\"\\nOverfitting Gap (F1): {overfitting_gap:.4f}\")\n",
    "    \n",
    "    if overfitting_gap > 0.1:\n",
    "        print(\"\\nWarning: Potential overfitting (F1 gap > 0.1)\")\n",
    "    elif overfitting_gap > 0.05:\n",
    "        print(\"\\nNote: Moderate overfitting (F1 gap > 0.05)\")\n",
    "    else:\n",
    "        print(\"\\nNo significant overfitting detected\")\n",
    "    \n",
    "    return y_proba_test, optimal_threshold\n",
    "\n",
    "# ======================\n",
    "# MODIFIED MAIN EXECUTION FOR MULTIPLE THRESHOLDS\n",
    "# ======================\n",
    "def evaluate_multiple_thresholds(hourly_with_indicators, threshold_list):\n",
    "    \"\"\"Evaluate model performance across multiple threshold percentages with consistent test set\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Create base dataset (without target)\n",
    "    daily_data_full = create_daily_dataset(hourly_with_indicators, threshold_pct=1.0)  # Dummy threshold\n",
    "    X_full = daily_data_full[[c for c in daily_data_full.columns if c not in ['open','high','low','close','volume','target']]]\n",
    "    \n",
    "    # Single time-based split for all thresholds\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_idx, test_idx in tscv.split(X_full):\n",
    "        X_train, X_test = X_full.iloc[train_idx], X_full.iloc[test_idx]\n",
    "        y_train_all, y_test_all = daily_data_full.iloc[train_idx], daily_data_full.iloc[test_idx]\n",
    "    \n",
    "    # Get consistent latest observation across all thresholds\n",
    "    last_data = X_test.iloc[[-1]]\n",
    "    last_timestamp = last_data.index[0]\n",
    "    last_open = daily_data_full.loc[last_timestamp, 'open']\n",
    "    last_low = daily_data_full.loc[last_timestamp, 'low']\n",
    "    \n",
    "    for threshold_pct in threshold_list:\n",
    "        \n",
    "        # Create targets for price DECREASE using consistent splits\n",
    "        y_train = (y_train_all['low'] <= y_train_all['open']*(1 - threshold_pct/100)).astype(int)\n",
    "        y_test = (y_test_all['low'] <= y_test_all['open']*(1 - threshold_pct/100)).astype(int)\n",
    "        \n",
    "        # Train model\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            max_depth=4,\n",
    "            learning_rate=0.03,\n",
    "            n_estimators=150,\n",
    "            scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),\n",
    "            early_stopping_rounds=20\n",
    "        )\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Optimal threshold selection\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "        f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
    "        optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        \n",
    "        # Latest prediction\n",
    "        last_proba = model.predict_proba(last_data)[0,1]\n",
    "        last_pred = int(last_proba >= optimal_threshold)\n",
    "        actual_move = int(last_low <= last_open*(1 - threshold_pct/100))\n",
    "        \n",
    "        # Test set metrics\n",
    "        y_pred = (y_proba >= optimal_threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        # Calculate train metrics\n",
    "        y_proba_train = model.predict_proba(X_train)[:,1]\n",
    "        y_pred_train = (y_proba_train >= optimal_threshold).astype(int)\n",
    "        tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_pred_train).ravel()\n",
    "        \n",
    "        results.append({\n",
    "            'Threshold (%)': threshold_pct,\n",
    "            'Optimal_Threshold': optimal_threshold,\n",
    "            # Test metrics\n",
    "            'Test_Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Test_Precision': precision_score(y_test, y_pred),\n",
    "            'Test_Recall': recall_score(y_test, y_pred),\n",
    "            'Test_F1': f1_score(y_test, y_pred),\n",
    "            'Test_Sensitivity': tp/(tp+fn),\n",
    "            'Test_Specificity': tn/(tn+fp),\n",
    "            # Train metrics\n",
    "            'Train_Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "            'Train_Precision': precision_score(y_train, y_pred_train),\n",
    "            'Train_Recall': recall_score(y_train, y_pred_train),\n",
    "            'Train_F1': f1_score(y_train, y_pred_train),\n",
    "            'Train_Sensitivity': tp_train/(tp_train+fn_train),\n",
    "            'Train_Specificity': tn_train/(tn_train+fp_train),\n",
    "            # Overfitting gaps\n",
    "            'Accuracy_Gap': accuracy_score(y_train, y_pred_train) - accuracy_score(y_test, y_pred),\n",
    "            'F1_Gap': f1_score(y_train, y_pred_train) - f1_score(y_test, y_pred),\n",
    "            # Prediction info\n",
    "            'Latest_Proba': last_proba,\n",
    "            'Latest_Pred': last_pred,\n",
    "            'Actual_Move': actual_move,\n",
    "            'Open_Price': last_open,\n",
    "            'Target_Price': last_open * (1 - threshold_pct/100),\n",
    "            'Timestamp': last_timestamp.strftime('%Y-%m-%d'),\n",
    "            'Current_Time_UTC+3': (datetime.utcnow() + timedelta(hours=3)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Fetching hourly data...\")\n",
    "    hourly_data = fetch_hourly_data(SYMBOL, START_DATE)\n",
    "    \n",
    "    print(\"Calculating indicators...\")\n",
    "    hourly_with_indicators = calculate_hourly_indicators(hourly_data)\n",
    "    \n",
    "    print(\"Evaluating multiple thresholds...\")\n",
    "    results_df = evaluate_multiple_thresholds(hourly_with_indicators, THRESHOLD_PCT)\n",
    "    \n",
    "    # Print summary of all thresholds\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"SUMMARY OF ALL THRESHOLDS (PRICE DECREASE PREDICTION)\".center(120))\n",
    "    print(\"=\"*120)\n",
    "    print(results_df.round(2).to_string(index=False, justify='center'))\n",
    "    print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853db370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
